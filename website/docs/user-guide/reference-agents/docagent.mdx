---
title: DocAgent
sidebarTitle: DocAgent
---

In the realm of AI and automation, handling documents and extracting information efficiently is of utmost importance.
[`DocAgent`](/docs/api-reference/autogen/agents/experimental/DocAgent) introduces an agentic solution to this problem. It handles document ingestion and query tasks seamlessly with natural language instructions, leveraging a streamlined internal architecture to provide efficient document processing and information retrieval.

<Tip>
DocAgent is designed to be production-ready and supports your RAG needs with a simplified, efficient architecture. It uses either a local vector Chroma database (default) or an in-memory option (InMemoryQueryEngine) for flexible deployment scenarios.

DocAgent continues to be developed and your feedback and [contributions](https://docs.ag2.ai/latest/docs/contributor-guide/contributing) are most welcome!
</Tip>

## Installation

Install AG2 with the `rag` extra to install the necessary packages for the DocAgent.

```bash
pip install ag2[openai,rag]
```

## Capabilities

The document agent can perform the following tasks:
1. Ingest documents from a local file or URL. Supported formats:

    - PDF
    - DOCX (DOCX, DOTX, DOCM, DOTM)
    - XLSX
    - PPTX (PPTX, POTX, PPSX, PPTM, POTM, PPSM)
    - HTML
    - ASCIIDOC (ADOC, ASCIIDOC, ASC)
    - MD (MD, MARKDOWN)
    - XML (XML, NXML)
    - TXT
    - JSON
    - CSV
    - IMAGE (BMP, JPG, JPEG, PNG, TIFF, TIF)
2. Answer questions with RAG capability and optional citation support

<Tip>
DocAgent answers questions only related to ingested documents, even when using an LLM it won't answer general knowledge questions.
</Tip>

## Architecture

[`DocAgent`](/docs/api-reference/autogen/agents/experimental/DocAgent) employs a simplified, efficient architecture that streamlines document processing through a coordinated group of specialized agents. This design reduces complexity while maintaining robust functionality.

### Architecture Overview

<!-- Architecture diagram placeholder -->
<div style="text-align: center; margin: 2rem 0; padding: 2rem; border: 2px dashed #ccc; border-radius: 8px; background-color: #f9f9f9;">
  <p><strong>DocAgent Architecture Diagram</strong></p>
  <img src="DocAgent_Architecture.png" alt="DocAgent Architecture Diagram showing the flow between DocumentTriageAgent, TaskManagerAgent, and SummaryAgent" style="max-width: 600px; width: 100%; margin-bottom: 1rem;" />
</div>

### Internal Agents

[`DocAgent`](/docs/api-reference/autogen/agents/experimental/DocAgent) orchestrates three specialized agents in a streamlined workflow:

- **DocumentTriageAgent**: Analyzes user requests and creates structured `DocumentTask` objects using structured output format
- **TaskManagerAgent**: Processes documents and queries using integrated tools with concurrent execution capabilities
- **SummaryAgent**: Provides comprehensive summaries of all completed operations with citation support

### Workflow

The DocAgent follows a linear, efficient workflow:

1. **Request Analysis**: The `DocumentTriageAgent` receives user requests and categorizes them into structured `DocumentTask` objects containing ingestions and queries
2. **Task Execution**: The `TaskManagerAgent` processes documents and queries concurrently using integrated tools:
   - `ingest_documents`: Handles document ingestion with concurrent processing
   - `execute_query`: Executes queries with optional citation support
3. **Summary Generation**: The `SummaryAgent` provides a comprehensive summary of all operations, including citations when enabled

### Key Features

- **Structured Task Processing**: Uses Pydantic models for reliable task categorization
- **Concurrent Execution**: Both document ingestion and query processing support concurrent operations
- **Citation Support**: Optional citation support with configurable chunk sizes
- **Persistent Context**: Maintains document state across interactions
- **Error Handling**: Robust error handling with detailed logging

## Configuration Options

### Basic Configuration

```python
from autogen import LLMConfig
from autogen.agents.experimental import DocAgent

llm_config = LLMConfig({"api_type": "openai", "model": "gpt-5-nano"})

# Basic DocAgent with default settings
doc_agent = DocAgent(llm_config=llm_config)
```

### Advanced Configuration

```python
# DocAgent with custom configuration
doc_agent = DocAgent(
    name="custom_doc_agent",
    llm_config=llm_config,
    parsed_docs_path="./custom_parsed_docs",
    collection_name="my_documents",
    enable_citations=True,
    citation_chunk_size=1024,
    update_inner_agent_system_message={
        "DocumentTriageAgent": "Custom triage instructions...",
        "TaskManagerAgent": "Custom task management instructions...",
        "SummaryAgent": "Custom summary instructions..."
    }
)
```

### Configuration Parameters

- `name`: Custom name for the DocAgent instance
- `llm_config`: LLM configuration for all internal agents
- `parsed_docs_path`: Directory for storing parsed documents (default: `"./parsed_docs"`)
- `collection_name`: Unique name for vector store collection
- `query_engine`: Custom RAG query engine (optional)
- `enable_citations`: Enable citation support in queries (default: `False`)
- `citation_chunk_size`: Size of chunks for citations (default: `512`)
- `update_inner_agent_system_message`: Custom system messages for internal agents

## Parsing Documents and Web Pages

Internally, DocAgent uses [Docling](https://github.com/DS4SD/docling) to convert documents into Markdown files, which are then ingested into the data store for querying.

For files (whether local files or URLs that point to files), DocAgent will download those files for Docling to convert. If it's a web page, DocAgent will use [Selenium](https://github.com/SeleniumHQ/Selenium) to browse to the page and extract the content.

## Data Store and Query Engine

DocAgent supports two different data stores and query engines for flexible deployment scenarios.

### Vector Store: Chroma Database

[Chroma](https://www.trychroma.com/) is a popular, open-source, vector database. DocAgent takes the Markdown and embeds and stores the data into the vector database.

This requires the `OPENAI_API_KEY` environment variable as OpenAI's GPT-4o model is used to create the embeddings.

DocAgent uses [LlamaIndex](https://github.com/run-llama/llama_index)'s vector store library to embed and query the Chroma database.

This is the default data store and query engine, so you do not need to create it and pass it to the DocAgent.

See the section on Collections below to understand how to use them effectively.

### In-Memory Query Engine

DocAgent can also store the Docling Markdown in memory when digesting documents.

When it comes time to query, DocAgent will inject the Markdown into the system message of an internal query agent and use an LLM to respond to the question.

Important notes about using the in-memory query engine:

- The full Markdown content from ingested documents is put into the context window, so be cautious of putting too much content as it may exceed the LLM's context limits
- The Markdown is put into the start of the system message to maximize the chance of utilizing the LLM's caching ability and reduce cost
- As it's in-memory, ingested content will be lost when the agent is destroyed
- LLMs can be better at answering some queries than the vector store as they process all of the context to answer the query, but this comes at the cost of more token usage

To use the in-memory query engine, you will need to create it and pass it to the DocAgent:

```python
from autogen.agents.experimental import DocAgent, InMemoryQueryEngine

# Example LLM Config
llm_config_list = {"config_list": {"api_type": "openai", "model": "gpt-5-nano", "cache_seed": None}}

# Create our In-Memory Query Engine
inmemory_qe = InMemoryQueryEngine(llm_config=llm_config_list)

# Include the Query Engine when creating your DocAgent
doc_agent = DocAgent(
    name="doc_agent",
    query_engine=inmemory_qe,
    llm_config=llm_config_list,
)
```

## Example Usage

<Tip>
Document ingestion requires an LLM and will use OpenAI's GPT-4o. Please ensure you have an `OPENAI_API_KEY` environment variable set.
</Tip>

<Warning>
This agent is currently in our `experimental` namespace, indicating that we have tested the functionality but the agent's interface may change. Please use it with that in mind.

If you do find any bugs please [log an issue](https://github.com/ag2ai/ag2/issues) in the AG2 repository.
</Warning>

In the following example, we ask the [`DocAgent`](/docs/api-reference/autogen/agents/experimental/DocAgent) to ingest a document and provide a financial summary. The request is handled in natural language, and the output demonstrates the internal agents working together efficiently.

```python
from autogen import LLMConfig
from autogen.agents.experimental import DocAgent

llm_config = LLMConfig(config_list={"api_type": "openai", "model": "gpt-5"})

# Create our DocAgent
document_agent = DocAgent(llm_config=llm_config)

# Process document and query
response = document_agent.run(
    "Can you ingest ../test/agentchat/contrib/graph_rag/Toast_financial_report.pdf and tell me the fiscal year 2024 financial summary?",
    max_turns=1
)

# Process the response
response.process()
```

### Example with Citations

```python
# DocAgent with citation support
document_agent = DocAgent(
    llm_config=llm_config,
    enable_citations=True,
    citation_chunk_size=512
)

response = document_agent.run(
    "Ingest the document and explain the key financial metrics with citations",
    max_turns=1
)

response.process()
```

## Collections

By default, [`DocAgent`](/docs/api-reference/autogen/agents/experimental/DocAgent) will ingest documents into the same collection. Every time you run the agent, it will utilize this collection, enabling you to keep documents ingested across different runs.

However, if you want to run multiple [`DocAgent`](/docs/api-reference/autogen/agents/experimental/DocAgent)s or want to ingest into a clean or specific vector store collection, you can use the `collection_name` parameter when creating the agent to set a unique collection name.

```python
from autogen import LLMConfig
from autogen.agents.experimental import DocAgent

llm_config = LLMConfig({"api_type": "openai", "model": "gpt-5-nano"})

# Create our DocAgents with their own collections
# so that their ingested data and queries will be unique to them
document_agent_apple = DocAgent(
    collection_name="apple_financials",
    llm_config=llm_config,
)

document_agent_nvidia = DocAgent(
    collection_name="nvidia_financials",
    llm_config=llm_config,
)
```

## Performance Characteristics

The new DocAgent architecture provides several performance improvements:

- **Reduced Latency**: Streamlined 3-agent architecture reduces communication overhead
- **Concurrent Processing**: Both document ingestion and query execution support concurrent operations
- **Efficient Memory Usage**: Optimized context management and document persistence
- **Structured Processing**: Pydantic-based task categorization ensures reliable processing

## DocAgent Performance

How does it perform? See our [DocAgent Performance](/docs/user-guide/reference-agents/docagent-performance) page for the full breakdown on how it handles different tasks.

If you have tasks you'd like DocAgent to perform, please share them as an [Issue](https://github.com/ag2ai/ag2/issues) on our GitHub repo.

Summary:

| # | Task | Ingested | In-memory Query Engine | Chroma Query Engine |
| :---: | --- | :---: | :---: | :---: |
| 1 | URL to Markdown file, query to summarize | ‚úÖ | ‚úÖ | ‚úÖ |
| 2 | URL to Microsoft Word document, query highlights | ‚úÖ | ‚úÖ | ‚úÖ |
| 3 | URL to PDF annual report, query specific figures | ‚úÖ | ‚úÖ | ‚úÖ |
| 4 | URL to PDF document, query to explain | ‚úÖ | ‚úÖ | ‚úÖ |
| 5 | Local file, PDF, query to explain | ‚úÖ | ‚úÖ | ‚úÖ |
| 6 | URL to JPG of scanned invoice, query a figure | ‚ùå | üî∂ | ÔøΩÔøΩ |
| 7 | Local file, PNG of scanned invoice, query a figure | ‚ùå | ‚ùå | ‚ùå |
| 8 | URL to XLSX using a redirect URL, query table | ‚úÖ | üî∂ | ÔøΩÔøΩ |
| 9 | URL to XLSX, query data | ‚ùå | ÔøΩÔøΩ | ‚úÖ |
| 10 | URL to CSV, query a figure | ‚ùå | N/A | N/A |
| 11 | URL to CSV, query to summarize | ‚úÖ | ‚úÖ | ‚úÖ |
| 12 | URL with CSV, query unrelated | ‚úÖ | ‚úÖ | ‚úÖ |
| 13 | Local files, 2 x Markdowns, Query to compare | ‚úÖ | ‚úÖ | ‚úÖ |
| 14 | Local file, Markdown, unrelated query | ‚úÖ | ‚úÖ | ‚úÖ |
| 15 | Local file, Markdown, unrelated query but general knowledge | ‚úÖ | ‚úÖ | ‚úÖ |
| 16 | No files to ingest but has query | N/A | ‚úÖ | ‚úÖ |
| 17 | Local file, PDF of annual report, query a figure | ‚úÖ | ‚úÖ | ‚úÖ |
| 18 | Local file, Microsoft Word, query a figure | ‚úÖ | ‚úÖ | ‚ùå |
| 19 | URL to web page with query to summarize | ‚úÖ | ‚úÖ | ‚úÖ |
| 20a | Local files, PDF and DOCX, one query to cover both | ‚úÖ | ‚úÖ | ‚úÖ |
| 20b | Follow-up query to DocAgent| N/A | ‚úÖ | ‚ùå |


## Collections

By default, [`DocAgent`](/docs/api-reference/autogen/agents/experimental/DocAgent) will ingest documents into the same collection. Every time you run the agent it will utilise this collection, enabling you to keep documents ingested across different runs.

However, if you want to run multiple [`DocAgent`](/docs/api-reference/autogen/agents/experimental/DocAgent)s or want to ingest into a clean or specific vector store collection, you can use the `collection_name` parameter when creating the agent to set a unique collection name.

```python
from autogen import LLMConfig
from autogen.agents.experimental import DocAgent

llm_config = LLMConfig(config_list={"api_type": "openai", "model": "gpt-5"})

# Create our DocAgents with their own collections
# so that their ingested data and queries will be unique to them
document_agent_apple = DocAgent(
    collection_name="apple_financials",
    llm_config=llm_config,
)

document_agent_nvidia = DocAgent(
    collection_name="nvidia_financials",
    llm_config=llm_config,
)

...

```

## Further examples

See this [notebook](/docs/use-cases/notebooks/notebooks/agents_docagent) for more examples of using document agent.
